{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pandas](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/500px-Pandas_logo.svg.png)\n",
    "## What is it?\n",
    "`pandas` is an open source **Python** library for data analysis. Python has always been great for prepping and munging data, but it's never been great for analysis - you'd usually end up using **R** or loading it into a database and using SQL (or worse, Excel). **pandas** makes Python great for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `pandas` is a Python package providing fast, flexible, and expressive data structures designed to make working > with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building\n",
    "> block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming > the most powerful and flexible open source data analysis / manipulation tool available in any language. It is \n",
    "> already well on its way toward this goal.\n",
    "\n",
    "`pandas` is well suited for many different kinds of data:\n",
    "\n",
    "  - Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
    "  - Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
    "  - Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
    "  - Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
    "\n",
    "The two primary data structures of pandas, `Series` (1-dimensional) and `DataFrame` (2-dimensional), handle the vast majority of typical use cases in finance, statistics, social science, and many areas of engineering. For **R** users, `DataFrame` provides everything that **R**’s data.frame provides and much more. `pandas` is built on top of `numpy` and is intended to integrate well within a scientific computing environment with many other 3rd party libraries.\n",
    "\n",
    "Here are just a few of the things that pandas does well:\n",
    "\n",
    "  - Easy handling of missing data (represented as `nan`) in floating point as well as non-floating point data\n",
    "  - Size mutability: columns can be inserted and deleted from `DataFrame` and higher dimensional objects\n",
    "  - Automatic and explicit data alignment: objects can be explicitly aligned to a set of labels, or the user can simply ignore the labels and let `Series`, `DataFrame`, etc. automatically align the data for you in computations\n",
    "  - Powerful, flexible group by functionality to perform split-apply-combine operations on data sets, for both aggregating and transforming data\n",
    "  - Make it easy to convert ragged, differently-indexed data in other Python and NumPy data structures into `DataFrame` objects\n",
    "  - Intelligent label-based slicing, fancy indexing, and subsetting of large data sets\n",
    "  - Intuitive merging and joining data sets\n",
    "  - Flexible reshaping and pivoting of data sets\n",
    "  - Hierarchical labeling of axes (possible to have multiple labels per tick)\n",
    "  - Robust IO tools for loading data from flat files (CSV and delimited), Excel files, databases, and saving / loading data from the ultrafast HDF5 format\n",
    "  - Time series-specific functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "`pandas` introduces two new data structures to Python - `Series` and `DataFrame`, both of which are built on top of `numpy` (this means it's fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common way to import `pandas` is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "A `Series` is a one-dimensional object similar to an array, list, or column in a table. It will assign a labeled index to each item in the Series. By default, each item will receive an index label from 0 to N, where N is the length of the Series minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Series with an arbitrary list\n",
    "s = pd.Series([7, 'Tonda', 3.14, -1789710578, 'Blaník'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify an index to use when creating the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, 'Tonda', 3.14, -1789710578, 'Blaník'], index=['A', 'Z', 'C', 'Y', 'E'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also assign a name to the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, 'Tonda', 3.14, -1789710578, 'Blaník'], index=['A', 'Z', 'C', 'Y', 'E'], name='Stream')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Series` constructor can convert a dictonary as well, using the keys of the dictionary as its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Brno': 1000, 'Praha': 1300, 'Ostrava': 900, 'Plzeň': 1100,\n",
    "     'České Budějovice': 450, 'Nejdek': None}\n",
    "cities = pd.Series(d)\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the index to select specific items from the `Series` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['Praha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[['Praha', 'Brno', 'Ostrava']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use boolean indexing for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the values in a `Series` on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing based on the index\n",
    "print('Old value:', cities['Praha'])\n",
    "cities['Praha'] = 1400\n",
    "print('New value:', cities['Praha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing values using boolean logic\n",
    "print(cities[cities < 1000])\n",
    "print('\\n')\n",
    "cities[cities < 1000] = 750\n",
    "\n",
    "print(cities[cities < 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you aren't sure whether an item is in the `Series`? You can check using idiomatic Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Karlovy Vary' in cities)\n",
    "print('Plzeň' in cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations can be done using scalars and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide city values by 3\n",
    "cities / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square city values\n",
    "cities**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add two `Series` together, which returns a union of the two `Series` with the addition occurring on the shared index values. Values on either `Series` that did not have a shared index will produce a NULL/NaN (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cities[['Praha', 'Brno', 'Ostrava']])\n",
    "print('\\n')\n",
    "print(cities[['České Budějovice', 'Brno']])\n",
    "print('\\n')\n",
    "print(cities[['Praha', 'Brno', 'Ostrava']] + cities[['České Budějovice', 'Brno']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that because Ostrava, Praha, and České Budějovice were not found in **both** Series, they were returned with NULL/NaN values.\n",
    "\n",
    "NULL checking can be performed with isnull and notnull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a boolean series indicating which values aren't NULL\n",
    "cities.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use boolean logic to grab the NULL cities\n",
    "print(cities.isnull())\n",
    "print('\\n')\n",
    "print(cities[cities.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "A `DataFrame` is a tablular data structure comprised of rows and columns, akin to a spreadsheet, database table, or R's data.frame object. You can also think of a `DataFrame` as a group of `Series` objects that share an index (the column names).\n",
    "\n",
    "For the rest of the tutorial, we'll be primarily working with `DataFrames`.\n",
    "\n",
    "### Different ways to create Pandas Dataframe\n",
    "Pandas `DataFrame` can be created in multiple ways. Let’s discuss different ways to create a `DataFrame` one by one.\n",
    "#### Method #1: Creating Pandas DataFrame from lists of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of lists \n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "  \n",
    "# print dataframe. \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method #2: Creating DataFrame from dict of narray/lists\n",
    "To create `DataFrame` from dictionary of narray/list, all the narray must be of same length. If index is passed then the length index should be equal to the length of arrays. If no index is passed, then by default, index will be range(n) where n is the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise dict of lists. \n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'], \n",
    "        'Age':[20, 21, 19, 18]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data) \n",
    "  \n",
    "# Print the output. \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise dict of lists. \n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'], \n",
    "        'Age':[20, 21, 19, 18]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data, index=['P1', 'P2', 'P3', 'P4']) \n",
    "  \n",
    "# Print the output. \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method #4: Creating Dataframe from list of dicts\n",
    "Pandas `DataFrame` can be created by passing lists of dictionaries as a input data. By default dictionary keys taken as columns. Note that missing values are filled as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise data to lists. \n",
    "data = [{'a': 1, 'b': 2, 'c':3}, \n",
    "        {'a':10, 'b': 20, 'c': 30},\n",
    "        {'a':30, 'b': 63}] \n",
    "  \n",
    "# Creates DataFrame. \n",
    "df = pd.DataFrame(data, index =['first', 'second', 'third']) \n",
    "  \n",
    "# Print the data \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method #5: Creating DataFrame using zip() function.\n",
    "\n",
    "Two or more lists can be merged by using `zip()` function and passed to `pd.DataFrame()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List1  \n",
    "Name = ['tom', 'krish', 'nick', 'juli']  \n",
    "    \n",
    "# List2  \n",
    "Age = [25, 30, 26, 22]  \n",
    "    \n",
    "# pandas Dataframe.  \n",
    "df = pd.DataFrame(zip(Name, Age), columns = ['Name', 'Age'])  \n",
    "     \n",
    "# Print data.  \n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "There are several other methods which could be used to [create or initialize Pandas DataFrame](https://towardsdatascience.com/15-ways-to-create-a-pandas-dataframe-754ecc082c17)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index from column\n",
    "Index could be also created from existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'rok': [2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016],\n",
    "        'přihlášeno': [1524, 1607, 1793, 1751, 1629, 1563, 1564, 1415],\n",
    "        'přijato': [964, 1130, 1168, 1031, 1077, 1114, 1092, 1018]}\n",
    "prfuk = pd.DataFrame(data)\n",
    "prfuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = prfuk.set_index('rok')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to easily access data based on 'rok'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new values could be calculated and assigned to new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfuk['úspěšnost'] = prfuk['přijato'] / prfuk['přihlášeno']\n",
    "prfuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you like to change formatting style? You can do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfuk.style.format({\n",
    "    'přihlášeno': '{:,d}'.format,\n",
    "    'přijato': '{:,d}'.format,\n",
    "    'úspěšnost': '{:.2%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more often, you'll have a dataset you want to read into a DataFrame. Let's go through several common ways of doing so.\n",
    "\n",
    "### CSV\n",
    "\n",
    "Reading a CSV is as simple as calling the read_csv function. By default, the read_csv function expects the column separator to be a comma, but you can change that using the sep parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: baseball-reference.com/players/r/riverma01.shtml\n",
    "!head -n 5 titanic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstation of pandas on Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` various reader functions have many parameters allowing you to do things like skipping lines of the file, parsing dates, or specifying how to handle NA/NULL datapoints.\n",
    "\n",
    "There's also a set of writer functions for writing to a variety of formats (CSVs, HTML tables, JSON). They function exactly as you'd expect and are typically called to_format:\n",
    "\n",
    "    my_dataframe.to_csv('path_to_file.csv')\n",
    "\n",
    "Take a look at [the IO documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) to familiarize yourself with file reading/writing functionality.\n",
    "\n",
    "### Excel\n",
    "\n",
    "Know who hates VBA? Me. I bet you do, too. Thankfully, pandas allows you to read and write Excel files, so you can easily read from Excel, write your code in Python, and then write back out to Excel - no need for VBA. Check [`read_excel()`](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-excel-reader) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From internet\n",
    "\n",
    "You can also read data directly from internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental and cumulative daily numbers of people with proven COVID-19 disease according to reports from regional hygiene stations, including laboratories.\n",
    "url = 'https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/nakaza.csv'\n",
    "df2 = pd.read_csv(url)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with DataFrames\n",
    "\n",
    "Now that we can get data into a DataFrame, we can finally start working with them. **pandas** has an abundance of functionality, far too much for me to cover in this introduction. I'd encourage anyone interested in diving deeper into the library to check out its [excellent documentation](http://pandas.pydata.org/pandas-docs/stable/). Or just use Google - there are a lot of Stack Overflow questions and blog posts covering specifics of the library.\n",
    "\n",
    "So back to our titanic dataset. Get some information about it.\n",
    "\n",
    "### Inspection\n",
    "**pandas** has a variety of functions for getting basic information about your DataFrame, the most basic of which is using the info method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells a few things about our DataFrame.\n",
    "\n",
    " - It's obviously an instance of a DataFrame.\n",
    " - Each row was assigned an index of 0 to N-1, where N is the number of rows in the DataFrame. pandas will do this by default if an index is not specified. Don't worry, this can be changed later.\n",
    " - There are 891 rows (every row must have an index).\n",
    " - Our dataset has 15 columns, where few has missing some values (age, embarked, deck and embark_town).\n",
    " - The last datatypes of each column, but not necessarily in the corresponding order to the listed columns. You should use the dtypes method to get the datatype for each column.\n",
    " - An approximate amount of RAM used to hold the DataFrame. See the .memory_usage method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame's also have a describe method, which is great for seeing basic statistics about the dataset's numeric columns. Be careful though, since this will return information on all columns of a numeric datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that I've used the head method regularly throughout this lecture - by default, head displays the first five records of the dataset, while tail displays the last five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Python's regular slicing syntax works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[10:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataset dimensions.. how many row and columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print column names and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data\n",
    "\n",
    "You can think of a DataFrame as a group of Series that share an index (in this case the column headers). This makes it easy to select specific columns.\n",
    "\n",
    "Selecting a single column from the DataFrame will return a Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns, simply pass a list of column names to the DataFrame, the output of which will be a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['age', 'survived']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting with conditions\n",
    "Row selection can be done multiple ways, but doing so by an individual index or boolean indexing are typically easiest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age[df.age > 35].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age > 35].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data using `iloc`\n",
    "The `iloc` indexer for Pandas Dataframe is used for integer-location based indexing / selection by position.\n",
    "\n",
    "The iloc indexer syntax is `df.iloc[<row selection>, <column selection>]`, which is sure to be a source of confusion for R users. `iloc` in pandas is used to select rows and columns by number, in the order that they appear in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single selections using iloc and DataFrame\n",
    "# Rows:\n",
    "df.iloc[0] # first row of data frame (Aleshia Tomkiewicz) - Note a Series data type output.\n",
    "df.iloc[1] # second row of data frame (Evan Zigomalas)\n",
    "df.iloc[-1] # last row of data frame (Mi Richan)\n",
    "# Columns:\n",
    "df.iloc[:,0] # first column of data frame (first_name)\n",
    "df.iloc[:,1] # second column of data frame (last_name)\n",
    "df.iloc[:,-1] # last column of data frame (id)\n",
    "# Multiple row and column selections using iloc and DataFrame\n",
    "df.iloc[0:5] # first five rows of dataframe\n",
    "df.iloc[:, 0:2] # first two columns of data frame with all rows\n",
    "df.iloc[[0,3,6,24], [0,5,6]] # 1st, 4th, 7th, 25th row + 1st 6th 7th columns.\n",
    "df.iloc[:5, -3:] # first 5 rows and last 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1, 50, 300]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data using “loc”\n",
    "The Pandas loc indexer can be used with DataFrames for selecting rows by label/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = prfuk.set_index('rok')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[[2011, 2013, 2015]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r['přijato'] > 1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[r['přijato'] > 1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[r['přijato'] > 1100, 'úspěšnost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[r['přijato'] > 1100, ['úspěšnost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[r['přijato'] > 1100, ['přijato', 'úspěšnost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplified rules of indexing are:\n",
    "\n",
    " - Use `loc` for label-based indexing or boolean\n",
    " - Use `iloc` for positional indexing\n",
    "\n",
    "### Examples\n",
    "Only age, sex and pclass of baby passengers (younger than 1 year), who have survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.survived == 1 ) & (df.age <= 2 ), ['age', 'sex', 'pclass']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "How many people survived and what is the percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.survived == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.survived[df.survived == 1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_counts()` provides occurance of each unique values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.survived == 1].sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a simple cross-tabulation\n",
    "Cross tabulation between gender and survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.sex, df.survived )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['class'], df.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross tabulation between passenger class and from where they embarked the ship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.pclass, df.embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.survived[df.age < 5].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.hist(bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df.age, df.fare, 'g*');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fare.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fare[df.sex == 'male'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fare[df.sex == 'female'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "By `group by` we are referring to a process involving one or more of the following steps\n",
    "\n",
    " - **Splitting** the data into groups based on some criteria\n",
    " - **Applying** a function to each group independently\n",
    " - **Combining** the results into a data structure\n",
    "\n",
    "Of these, the split step is the most straightforward. In fact, in many situations you may wish to split the data set into groups and do something with those groups yourself. In the apply step, we might wish to one of the following:\n",
    "\n",
    " - Aggregation: computing a summary statistic (or statistics) about each group. Some examples:\n",
    "\n",
    "    - Compute group sums or means\n",
    "    - Compute group sizes / counts\n",
    "    - Transformation: perform some group-specific computations and return a like-indexed. Some examples:\n",
    "\n",
    " - Standardizing data (zscore) within group\n",
    "    - Filling NAs within groups with a value derived from each group\n",
    "    - Filtration: discard some groups, according to a group-wise computation that evaluates True or False. Some examples:\n",
    "\n",
    " - Discarding data that belongs to groups with only a few members\n",
    "    - Filtering out data based on the group sum or mean\n",
    " - Some combination of the above: GroupBy will examine the results of the apply step and try to return a sensibly combined result if it doesn’t fit into either of the above two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'X' : ['B', 'B', 'A', 'A'], 'Y' : [1, 2, 3, 4]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(['X']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(['X']).get_group('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('who')['fare'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('who')['fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot('age', by='who');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
